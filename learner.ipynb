{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435febec",
   "metadata": {},
   "source": [
    "# Learnability Project: PFA Phonotactic Learner\n",
    "\n",
    "------\n",
    "\n",
    "## General functions and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "847077f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfoma import FST, State\n",
    "\n",
    "lam = \"λ\"\n",
    "\n",
    "\n",
    "def data_iterator(path):\n",
    "    \"\"\"Yield a word as a list of tokens\"\"\"\n",
    "    with open (path, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            yield line.split()\n",
    "            \n",
    "            \n",
    "def make_alphabet(path) -> list:\n",
    "    \"\"\"This function extracts an alphabet from a corpusl\"\"\"\n",
    "    alph = []\n",
    "    for word in data_iterator(path):\n",
    "        for sym in word:\n",
    "            if sym not in alph:\n",
    "                alph.append(sym)\n",
    "    return alph\n",
    "\n",
    "def get_trans_sum(state):\n",
    "    \"\"\"sums all the transition weights (counts) and the finalweight for given state \"\"\"\n",
    "    return sum([tran.weight for _, tran in state.all_transitions()])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e70fc",
   "metadata": {},
   "source": [
    "## Strictly 2-Local Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f50f441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_SL2_dfa(alphabet:list) -> FST:\n",
    "    \"\"\"This function initializes a 2-SL PFA according to an alphabet. All weights are set to 0 by default\"\"\"\n",
    "    \n",
    "    # create the FST object and instantiate the initial state\n",
    "    dfa = FST()\n",
    "    q0 = dfa.initialstate\n",
    "    q0.finalweight = 0\n",
    "    q0.name = lam\n",
    "    states = {q0,}\n",
    "    \n",
    "    # initialize all states and connect q0 to them\n",
    "    for sym in alphabet:\n",
    "        q = State()\n",
    "        q.name = sym\n",
    "        q0.add_transition(q, sym, 0)\n",
    "        states.add(q)\n",
    "        q.finalweight = 0\n",
    "    \n",
    "    # loopify the states, excluding q0\n",
    "    states_no_q0 = set([s for s in states if s.name != lam])\n",
    "    for state1 in states_no_q0:\n",
    "        for state2 in states_no_q0:\n",
    "            state1.add_transition(state2, state2.name, 0)\n",
    "    \n",
    "    dfa.states      = states\n",
    "    dfa.finalstates = states\n",
    "    dfa.alphabet    = alphabet\n",
    "    return dfa\n",
    "\n",
    "def update_SL(dfa:FST, path:str) -> FST:\n",
    "    \"\"\"\n",
    "    This function takes a 2SL dfa and updates each transition whenever it is \"passed through\".\n",
    "    \n",
    "    More specifically, for each word, it iterates over the outgoing transitions for each state, checks which transition label\n",
    "    matches the current token in the word, and then increments that transition's weight by 1.\n",
    "    \n",
    "    Each time a string ends in a state, that state's `finalweight` attribute is also incremented by 1.\n",
    "    \"\"\"\n",
    "    for word in data_iterator(path):\n",
    "        cs = dfa.initialstate # gets set back to q0 when a new word is processed\n",
    "        for token in word:\n",
    "            for _, trans in cs.all_transitions():\n",
    "                \n",
    "                if trans.label == token: # find the transition that matches the current token\n",
    "                    trans.weight += 1\n",
    "                    cs = trans.targetstate # update cs to transition's target state. This is how we \"traverse\" the states\n",
    "                    \n",
    "        cs.finalweight += 1 # update the weight of the last state the current string ends in\n",
    "    return dfa\n",
    "\n",
    "def MLE_SL(dfa:FST, path:str) -> FST:\n",
    "    \"\"\"This function takes a SL DFA, updates its weights from a corpus, and normalizes\"\"\"\n",
    "    dfa = update_SL(dfa, path)\n",
    "    \n",
    "    #  list of state weight sums \n",
    "    all_state_trans_sums = [get_trans_sum(state) + state.finalweight for state in dfa.states] \n",
    "    \n",
    "    for i, state in enumerate(dfa.states):\n",
    "        for _, trans in state.all_transitions():\n",
    "            \n",
    "            #  normalize transition weight by sum of the state's transition weights\n",
    "            trans.weight = (trans.weight) / all_state_trans_sums[i]\n",
    "            \n",
    "        state.finalweight = (state.finalweight / all_state_trans_sums[i])\n",
    "\n",
    "    # assert that each state's transition weights sum to 1\n",
    "    for state in dfa.states:\n",
    "        try:\n",
    "            total = sum([t.weight for _, t in state.all_transitions()]) + state.finalweight\n",
    "            assert total > .99 # accounts for floating point precision\n",
    "        except AssertionError:\n",
    "            print(f\"State: {state.name} is misbehaving!\\nWeighted sum: {total} != 1\\n\")\n",
    "            raise RuntimeError\n",
    "            \n",
    "\n",
    "    return dfa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0b535",
   "metadata": {},
   "source": [
    "## Strictly 2-Piecewise Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3b5ff15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_SP2_dfas(alphabet:list) -> list[FST]:\n",
    "    \"\"\"This function intitializes 2SP machines according the length of the alphabet\"\"\"\n",
    "    SP2_machines = []\n",
    "    \n",
    "    # initializes all 2 state machines and loopify them\n",
    "    for sym1 in alphabet:\n",
    "        dfa             = FST()\n",
    "        q0              = dfa.initialstate\n",
    "        q0.finalweight  = 0\n",
    "        q0.name         = lam\n",
    "        q1              = State()\n",
    "        q1.finalweight  = 0\n",
    "        q1.name         = sym1\n",
    "        dfa.states      = {q0, q1}\n",
    "        dfa.finalstates = {q0, q1}\n",
    "        dfa.alphabet    = alphabet\n",
    "        q0.add_transition(q1, sym1, 0)\n",
    "        \n",
    "        # loopification\n",
    "        for sym2 in alphabet:\n",
    "            if sym1 != sym2:\n",
    "                q0.add_transition(q0, sym2, 0)\n",
    "            \n",
    "            q1.add_transition(q1, sym2, 0)\n",
    "        \n",
    "        SP2_machines.append(dfa)\n",
    "     \n",
    "    return SP2_machines\n",
    "\n",
    "            \n",
    "        \n",
    "def update_SP(dfas:list[FST], path:str) -> list[FST]:\n",
    "    \n",
    "    # pass each word from corpus through all dfas and increment weights accordingly\n",
    "    for word in data_iterator(path):\n",
    "        for dfa in dfas:\n",
    "            \n",
    "            cs = dfa.initialstate\n",
    "            for token in word:\n",
    "                for _, trans in cs.all_transitions():\n",
    "                    \n",
    "                    # detect if transition brings us into new state\n",
    "                    if token == trans.targetstate.name: \n",
    "                        cs = trans.targetstate\n",
    "                        \n",
    "                    if trans.label == token:\n",
    "                        trans.weight += 1\n",
    "\n",
    "\n",
    "            \n",
    "        #cs.finalweight += 1\n",
    "                        \n",
    "    return dfas\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def MLE_SP(dfas:list[FST], path:str) -> list[FST]:\n",
    "    \n",
    "    dfas = update_SP(dfas, path)\n",
    "    \n",
    "    return dfas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b93056",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e44f14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: FST Pages: 1 -->\n",
       "<svg width=\"195pt\" height=\"123pt\"\n",
       " viewBox=\"0.00 0.00 195.39 122.70\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 118.7)\">\n",
       "<title>FST</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-118.7 191.39,-118.7 191.39,4 -4,4\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.7\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Σ: {a,b,c}</text>\n",
       "<!-- λ/0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>λ/0</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" stroke-width=\"2\" cx=\"29.35\" cy=\"-52.35\" rx=\"25.22\" ry=\"25.22\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" stroke-width=\"2\" cx=\"29.35\" cy=\"-52.35\" rx=\"29.2\" ry=\"29.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.35\" y=\"-48.65\" font-family=\"Times,serif\" font-size=\"14.00\">λ/0</text>\n",
       "</g>\n",
       "<!-- λ/0&#45;&gt;λ/0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>λ/0&#45;&gt;λ/0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M18.52,-80.07C18.03,-90.79 21.64,-99.7 29.35,-99.7 34.4,-99.7 37.7,-95.86 39.23,-90.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"42.73,-90.35 40.18,-80.07 35.76,-89.7 42.73,-90.35\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.35\" y=\"-103.5\" font-family=\"Times,serif\" font-size=\"14.00\">b/1, c/1</text>\n",
       "</g>\n",
       "<!-- a/0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>a/0</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"145.39\" cy=\"-52.35\" rx=\"24.87\" ry=\"24.87\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"145.39\" cy=\"-52.35\" rx=\"28.9\" ry=\"28.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"145.39\" y=\"-48.65\" font-family=\"Times,serif\" font-size=\"14.00\">a/0</text>\n",
       "</g>\n",
       "<!-- λ/0&#45;&gt;a/0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>λ/0&#45;&gt;a/0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.83,-52.35C73.2,-52.35 90.82,-52.35 106.33,-52.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.67,-55.85 116.67,-52.35 106.67,-48.85 106.67,-55.85\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.7\" y=\"-56.15\" font-family=\"Times,serif\" font-size=\"14.00\">a/2</text>\n",
       "</g>\n",
       "<!-- a/0&#45;&gt;a/0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>a/0&#45;&gt;a/0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.96,-79.22C134.37,-90 137.85,-99.05 145.39,-99.05 150.35,-99.05 153.55,-95.15 155,-89.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"158.5,-89.47 155.83,-79.22 151.53,-88.9 158.5,-89.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"145.39\" y=\"-102.85\" font-family=\"Times,serif\" font-size=\"14.00\">a/4, b/2, c/2</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7ff526b55c60>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learning data paths\n",
    "debug   = \"data/eric_debugging_data.txt\"\n",
    "toy     = \"data/LearningData.txt\"\n",
    "navajo  = \"data/LearningData_navajo.txt\"\n",
    "quechua = \"data/LearningData_quechua.txt\"\n",
    "\n",
    "toy_alph = make_alphabet(toy)\n",
    "debug_alph = make_alphabet(debug)\n",
    "\n",
    "db_SL2     = make_SL2_dfa(debug_alph)\n",
    "db_SL2_MLE = MLE_SL(db_SL2, debug)\n",
    "\n",
    "\n",
    "db_SP2     = make_SP2_dfas(debug_alph)\n",
    "db_SP2_MLE = MLE_SP(db_SP2, debug)\n",
    "\n",
    "db_SP2_MLE[0].view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a863161",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "sum log probs along path given string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194f791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c71604d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5931f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
