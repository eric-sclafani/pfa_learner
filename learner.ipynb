{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435febec",
   "metadata": {},
   "source": [
    "# Learnability Project: PFA Phonotactic Learner\n",
    "\n",
    "------\n",
    "\n",
    "## General functions and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847077f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfoma import FST, State\n",
    "\n",
    "Lfish = \"⋊\"\n",
    "Rfish = \"⋉\"\n",
    "\n",
    "\n",
    "def data_iterator(path):\n",
    "    \"\"\"Yield a word as a list of tokens\"\"\"\n",
    "    with open (path, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            yield line.split()\n",
    "            \n",
    "            \n",
    "def make_alphabet(path) -> list:\n",
    "    \"\"\"This function extracts an alphabet from a corpusl\"\"\"\n",
    "    alph = []\n",
    "    for word in data_iterator(path):\n",
    "        for sym in word:\n",
    "            if sym not in alph:\n",
    "                alph.append(sym)\n",
    "    return alph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e70fc",
   "metadata": {},
   "source": [
    "## Strictly 2-Local Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50f441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_SL2_dfa(alphabet:list) -> FST:\n",
    "    \"\"\"This function initializes a 2-SL PFA according to an alphabet. All weights are set to 0 by default\"\"\"\n",
    "    \n",
    "    # create the FST object and instantiate the initial state\n",
    "    dfa = FST()\n",
    "    q0 = dfa.initialstate\n",
    "    q0.finalweight = 0\n",
    "    q0.name = Lfish\n",
    "    states = {q0,}\n",
    "    \n",
    "    # initialize all states and connect q0 to them\n",
    "    for sym in alphabet:\n",
    "        q = State()\n",
    "        q.name = sym\n",
    "        q0.add_transition(q, sym, 0)\n",
    "        states.add(q)\n",
    "        q.finalweight = 0\n",
    "    \n",
    "    # loopify the states, excluding q0\n",
    "    states_no_q0 = set([s for s in states if s.name != Lfish])\n",
    "    for state1 in states_no_q0:\n",
    "        for state2 in states_no_q0:\n",
    "            state1.add_transition(state2, state2.name, 0)\n",
    "    \n",
    "    dfa.states      = states\n",
    "    dfa.finalstates = states\n",
    "    dfa.alphabet    = alphabet\n",
    "    return dfa\n",
    "\n",
    "def update_SL(dfa:FST, path:str) -> FST:\n",
    "    \"\"\"\n",
    "    This function takes a 2SL dfa and updates each transition whenever it is \"passed through\".\n",
    "    \n",
    "    More specifically, for each word, it iterates over the outgoing transitions for each state, checks which transition label\n",
    "    matches the current token in the word, and then increments that transition's weight by 1.\n",
    "    \n",
    "    Each time a string ends in a state, that state's `finalweight` attribute is also incremented by 1.\n",
    "    \"\"\"\n",
    "    for word in data_iterator(path):\n",
    "        cs = dfa.initialstate # gets set back to q0 when a new word is processed\n",
    "        for token in word:\n",
    "            for _, trans in cs.all_transitions():\n",
    "                \n",
    "                if trans.label == token: # find the transition that matches the current token\n",
    "                    trans.weight += 1\n",
    "                    cs = trans.targetstate # update cs to transition's target state. This is how we \"traverse\" the states\n",
    "                    \n",
    "        cs.finalweight += 1 # update the weight of the last state the current string ends in\n",
    "    return dfa\n",
    "\n",
    "def MLE_SL(dfa:FST, path:str) -> FST:\n",
    "    \n",
    "    dfa = update_SL(dfa, path)\n",
    "    \n",
    "    # sums all the transition weights (counts) and the finalweight for given state \n",
    "    get_trans_sum = lambda state: sum([tran.weight for _, tran in state.all_transitions()])\n",
    "    \n",
    "    # gets the sum of all transitions and finalweight for each state.\n",
    "    all_state_trans_sums = [get_trans_sum(state) + state.finalweight for state in dfa.states]\n",
    "    \n",
    "    for i, state in enumerate(dfa.states):\n",
    "        for _, trans in state.all_transitions():\n",
    "            \n",
    "            #  normalize transition weight by sum of the state's transition weights\n",
    "            trans.weight = (trans.weight) / all_state_trans_sums[i]\n",
    "            \n",
    "        state.finalweight = (state.finalweight / all_state_trans_sums[i])\n",
    "\n",
    "    # assert that each state's transition weights sum to 1\n",
    "    for state in dfa.states:\n",
    "        assert sum([t.weight for _, t in state.all_transitions()]) + state.finalweight == 1\n",
    "\n",
    "    return dfa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0b535",
   "metadata": {},
   "source": [
    "## Strictly 2-Piecewise Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5ff15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_SP2_dfas(alphabet:list) -> list[FST]:\n",
    "    \"\"\"This function intitializes 2SP machines according the length of the alphabet\"\"\"\n",
    "    SP2_machines = []\n",
    "    \n",
    "    # initializes all 2 state machines and loopify them\n",
    "    for sym1 in alphabet:\n",
    "        dfa             = FST()\n",
    "        q0              = dfa.initialstate\n",
    "        q0.finalweight  = 0\n",
    "        q0.name         = Lfish\n",
    "        q1              = State()\n",
    "        q1.finalweight  = 0\n",
    "        q1.name         = sym1\n",
    "        dfa.states      = {q0, q1}\n",
    "        dfa.finalstates = {q0, q1}\n",
    "        dfa.alphabet    = alphabet\n",
    "        q0.add_transition(q1, sym1, 0)\n",
    "        \n",
    "        # loopification\n",
    "        for sym2 in alphabet:\n",
    "            q1.add_transition(q1, sym2, 0)\n",
    "        \n",
    "        SP2_machines.append(dfa)\n",
    "     \n",
    "    return SP2_machines\n",
    "        \n",
    "def update_SP(dfas:list[FST], path:str) -> list[FST]:\n",
    "    \n",
    "    for dfa in dfas:\n",
    "        for word in data_iterator(path):\n",
    "            pass\n",
    "        \n",
    "        \n",
    "def MLE_SP(dfas:list[FST]) -> list[FST]:\n",
    "    \n",
    "    dfas = update_SP(dfas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b93056",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44f14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_alphabet = make_alphabet(\"data/eric_debugging_data.txt\")\n",
    "\n",
    "toy_SL2 = make_SL2_dfa(toy_alphabet)\n",
    "toy_SL2_MLE = MLE_SL(toy_SL2, \"data/eric_debugging_data.txt\")\n",
    "\n",
    "\n",
    "toy_2SP = make_SP2_dfas(toy_alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a863161",
   "metadata": {},
   "source": [
    "##  notes\n",
    "\n",
    "## ASK ABOUT THE EVALUATION STEP\n",
    "\n",
    "MLE(dfa, corpus) = dfa' \n",
    "\n",
    "create_SL2_dfa (alphabet\n",
    "\n",
    "getalphabet(corpus) = set_of_letters \n",
    "\n",
    "Q = all strings of length less than k\n",
    "\n",
    "I = \"\" \n",
    "\n",
    "F = Q\n",
    "\n",
    "delta(q,a) = k-1 suffix of qa \n",
    "\n",
    "example: (a,b) = k-1 suffix of ab which is b (k=2)\n",
    "\n",
    "Example; Suppose k=4. Then delta(aaa,b) = 3 suffix of aaab, which is aab \n",
    "\n",
    "Also if qa is of length less than k-1 than the k-1 suffix of qa is just qa \n",
    "\n",
    "3 suffix of aa is aa\n",
    "\n",
    "BIGRAM: all possible states given alphabet (given k)\n",
    "\n",
    "42 SP machines, 1 SL machine\n",
    "\n",
    "**NOTE:**\n",
    "Multi-symbol labels get delimited by colons when displayed via `render`. So, \"abc\" -> \"a:b:c\" (for some really odd reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194f791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
